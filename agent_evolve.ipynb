{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LiXFVSwVN1hD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\kiit\\anaconda3\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (2.159.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "pMIvetrJOsZB"
   },
   "outputs": [],
   "source": [
    "api_key=\"you gemini api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ShXpOuQDOvOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Tell me a joke\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x40x1o3Uy_6R"
   },
   "outputs": [],
   "source": [
    "def write(num:int,word:str):\n",
    "  if num<1:\n",
    "    print(\"Please select number grater than 0\")\n",
    "  for i in range(num):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTZQqux79nGu"
   },
   "outputs": [],
   "source": [
    "panda='''\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⢀⡤⠊⠉⠀⠀⠉⠑⢄⠀⣀⣠⠤⠴⠒⠒⠒⠦⠤⠤⣀⡀⣠⠴⠚⠉⠉⠈⠉⠓⢦⡀⠀⠀⠀\n",
    "⠀⠀⠀⠀⡞⠀⢀⡴⠚⠉⢁⡶⠚⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠓⢤⡒⠉⠓⢄⠀⠀⠀⢳⠀⠀⠀\n",
    "⠀⠀⠀⢸⠀⠀⡌⠀⠀⣠⠊⠀⠀⠀⣀⡤⠤⣄⠀⠀⠀⠀⠀⡴⠊⠉⠒⢤⡑⣄⠀⢸⠀⠀⠀⢸⠀⠀⠀\n",
    "⠀⠀⠀⢰⠀⠀⠸⢄⣰⠁⠀⠀⡴⠋⠀⠀⠀⠈⢧⠀⠀⠀⣸⠀⠀⣀⠀⠀⠱⡌⢦⡼⠀⠀⢠⠟⠀⠀⠀\n",
    "⠀⠀⠀⠈⠳⣄⣀⣰⠃⠀⢀⡞⠀⠀⢠⣾⣿⡆⣼⠀⠀⠀⣿⠀⣾⣿⣿⡄⠀⠹⡀⢣⣀⠴⠋⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⢀⠇⠀⠀⡾⠀⠀⠀⠸⣿⣿⣷⠃⠀⠀⠀⠈⢧⠻⠿⠿⠇⠀⠀⡇⠈⡆⠀⠀⠀⠀⠀⠀\n",
    "⣤⢤⠀⠀⠀⠀⡜⠀⠀⠀⠹⡄⠀⠀⠀⣠⠞⠁⣠⠔⠒⠒⠦⡌⠓⢤⣀⣀⣀⡠⠇⠀⢳⠀⠀⠀⠀⠀⠀\n",
    "⢧⡀⠣⡀⠀⢀⡇⠀⠀⠀⠀⠉⠓⠋⠉⠀⠀⠀⠧⣀⠀⠀⣠⠇⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⠀⠀⠀⠀\n",
    "⠀⠙⢄⠘⣄⠈⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⠀⢩⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⡟⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠹⣍⠣⡘⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠑⠢⠤⠾⠔⠂⠀⠀⠀⠀⠀⠀⢀⣠⡋⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠈⢢⡙⢞⠉⠓⠦⢄⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⡤⠔⠚⠉⠀⠈⠳⣄⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⢠⠞⠙⢄⠱⣄⠀⡴⠈⠉⠙⠒⠒⠒⠒⠒⠒⠒⠋⠉⠁⠀⠀⢢⠀⠀⠀⠀⠀⠈⢆⠀⠀⠀⠀\n",
    "⠀⠀⠀⢠⠃⠀⠀⠐⠓⠋⠙⠛⠲⣄⢀⡠⠔⠚⠋⠉⠉⠉⠉⠓⠲⢤⣀⠈⣧⠤⠒⠒⠀⠀⠘⡇⠀⠀⠀\n",
    "⠀⠀⠀⢈⠀⠀⠀⠀⠀⠀⠀⠀⣛⠛⢯⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣿⣷⠄⠀⠀⠀⠀⠀⡇⠀⠀⠀\n",
    "⠀⠀⠀⠸⣆⠀⠀⠀⠀⠀⠀⢈⡛⢁⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠃⣶⡆⠀⠀⠀⠀⢠⡇⠀⠀⠀\n",
    "⠀⠀⠀⠀⠈⢹⡶⠤⣤⣠⣤⡬⠷⢯⡜⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢧⣘⣛⣀⣀⣠⡴⠯⠤⢄⡀⠀\n",
    "⠀⠀⠀⢀⠖⠉⢀⣀⣀⣀⠉⠳⣄⠀⠘⢆⠙⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣨⠟⠋⣁⣀⣀⡀⠀⠙⣆\n",
    "⠀⠀⢠⡏⢠⠚⡿⢧⣏⣻⠉⠢⡌⢣⡀⠀⠑⣄⠇⠀⠀⠀⠀⠀⠀⠀⠀⢀⡜⡡⠒⢻⣉⣷⡤⡉⢢⠀⢸\n",
    "⠀⠀⠘⡇⠇⣠⣷⠜⢀⠤⠒⠢⡈⢦⣱⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⠟⢠⠖⠒⠯⡘⢶⠧⣀⣀⠏\n",
    "⠀⠀⠀⠹⣾⡷⠼⠀⡏⠀⠀⢠⠃⠀⠹⡗⠲⠤⠤⠤⠤⠤⠤⠴⠖⠒⢹⡏⠀⢹⡀⠀⢀⡇⠐⣶⡿⠋⠀\n",
    "⠀⠀⠀⠀⠈⠻⣦⡀⠙⠒⠊⠁⠀⠀⣠⡧⠤⠔⠒⠒⠒⠒⠒⠋⠁⠒⠺⣧⡀⠀⠈⢉⣉⡤⠖⠋⠁⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠉⠉⠒⠒⠒⠒⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠉⠀⠀⠀⠀⠀⠀⠀\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-mrZokZ1-Q6k"
   },
   "outputs": [],
   "source": [
    "elephant='''\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⣤⣶⣶⠶⠾⠿⠛⠛⠛⠛⠛⠛⠛⠿⠿⠶⣶⣶⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣴⡿⠟⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠻⠿⣶⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⡾⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⢿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⡿⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⣤⣤⣤⣶⡿⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢻⣶⣦⣤⣤⣄⣀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⢀⣠⣴⠾⠿⠛⢉⣉⡠⣴⡿⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⣦⠄⢉⣉⠛⠻⠿⣶⣤⣀⠀⠀⠀\n",
    "⠀⢀⣴⠟⠋⣡⠤⠒⠋⠁⠀⢀⣿⠃⠀⠀⠀⠀⠀⠀⠀⢀⣴⡾⠟⠛⠛⠛⠿⣦⡀⠀⠀⠀⢀⣴⠿⠛⠛⠛⠻⢷⣦⡀⠀⠀⠀⠀⠀⠀⠀⠘⣿⡄⠀⠀⠉⠒⠢⢄⡉⠻⣷⣄⠀\n",
    "⢰⡿⠁⡴⠋⠀⠀⠀⠀⠀⠀⢸⡿⠀⠀⠀⠀⠀⠀⠀⢠⣿⠋⠀⠀⠀⠀⠀⠀⠈⢿⣆⠀⣰⡿⠁⠀⠀⠀⠀⠀⠀⠙⢿⡄⠀⠀⠀⠀⠀⠀⠀⢿⡇⠀⠀⠀⠀⠀⠀⠈⠲⡈⢻⣇\n",
    "⣿⠃⣾⣀⡀⠀⠀⠀⠀⠤⠤⣼⡇⠀⠀⠀⠀⠀⠀⠀⣿⡇⠀⠀⠀⠀⣠⣤⣄⠀⠈⣿⣄⣿⠁⠀⣠⣤⣤⡀⠀⠀⠀⢸⣿⠀⠀⠀⠀⠀⠀⠀⢸⣧⠀⠀⠀⠀⠀⠤⢄⣀⣸⠀⣿\n",
    "⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⠇⠀⠀⠀⠀⠀⠀⠀⣿⡇⠀⠀⠀⢸⣿⣿⣿⡇⢀⣿⠋⣿⡀⠐⣿⣿⣿⡇⠀⠀⠀⢸⣿⠀⠀⠀⠀⠀⠀⠀⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿\n",
    "⢿⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠘⢿⣄⠀⠀⠀⠙⠛⠋⣠⣾⠏⠀⠹⣷⣄⠙⠛⠋⠀⠀⠀⣠⡿⠃⠀⠀⠀⠀⠀⠀⠀⣸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿\n",
    "⢸⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⢷⣶⣤⣤⣴⡾⠟⠁⠀⠀⠀⠈⠻⢷⣦⣤⣤⣶⡾⠟⠁⠀⠀⠀⠀⠀⠀⠀⢀⢣⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⣸⡏\n",
    "⠀⢻⣇⠀⠀⠀⠀⠀⠀⠀⠀⢿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡞⢸⣿⡇⠀⠀⠀⠀⠀⠀⠀⢠⣿⠃\n",
    "⠀⠀⢿⣆⠀⠀⠀⠀⠀⠀⠀⢸⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣶⡾⠟⠛⠿⢶⣦⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡞⠀⣾⣿⠀⠀⠀⠀⠀⠀⠀⢠⣿⠃⠀\n",
    "⠀⠀⠀⠻⣧⡀⠀⠀⠀⠀⠀⠈⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠁⠀⠀⠀⠀⠀⠈⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⠎⠀⢰⣿⡛⠀⠀⠀⠀⠀⠀⣴⡿⠁⠀⠀\n",
    "⠀⠀⠀⠀⠙⢿⣦⡀⠀⠀⠀⠀⠘⣿⡀⠀⠀⠀⠀⠀⣀⣀⡀⠀⠰⣶⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣶⠆⠀⣀⣀⡀⠀⠀⡴⠃⠀⢠⣿⢣⠇⠀⠀⠀⠀⣠⣾⠟⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⢸⡿⠿⣶⣄⣀⠀⠀⠘⣿⣄⠀⠀⣠⡿⠛⠛⠛⢿⣆⢻⣇⠀⠀⢠⣶⠾⠿⢷⣦⡄⠀⠀⢸⣿⣴⡿⠛⠛⠛⣿⡏⠀⠀⢠⣿⢃⠎⠀⣀⣠⣴⡿⢿⡇⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⢸⣇⠀⠈⠉⠛⠻⠿⠿⢿⣿⣷⢦⣿⠃⠀⠀⠀⣸⣿⠈⣿⡀⠀⠈⠁⠀⠀⠀⠈⠁⠀⠀⣿⢿⣿⠀⠀⠀⠀⠘⣿⠀⣴⡿⠿⠿⡿⠟⠛⠋⠁⠀⣼⡇⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠱⡹⣿⣿⠀⠀⠀⣰⣽⡟⠀⢹⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⠤⢿⣆⠀⠀⠀⠀⣿⡿⠋⠀⠀⡜⠀⠀⠀⠀⠀⡰⣿⠃⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⢿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠑⣬⣿⠀⠀⣰⣿⠟⠑⠒⢺⣇⠀⠀⣶⠿⠿⠷⣶⠀⠀⢸⡧⠀⠀⢻⣧⡀⠀⠀⣿⠁⠀⢠⠎⠀⠀⠀⠀⠀⡴⣹⡟⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠘⣿⡀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣿⣀⣾⡿⢿⣦⣄⣀⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⡇⣀⣠⣴⡿⢿⣦⣠⣿⢀⠔⠁⠀⠀⠀⠀⢀⠞⢀⣿⠃⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠹⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠛⠛⢄⠀⠈⠙⠛⠿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡿⠛⠋⠁⠀⠀⠙⣿⠗⠁⠀⠀⠀⠀⢀⡴⠁⠀⣾⠏⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠻⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠲⠤⣀⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⠀⠀⣀⡠⠔⠋⠀⠀⠀⠀⠀⢀⡴⠋⠀⢀⣼⠟⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣷⡀⠀⠀⢀⣤⡶⠿⠟⠛⠿⠷⣶⣤⣤⣀⠉⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡗⠒⢉⣠⣤⣴⡶⠿⠟⠛⠿⢷⣯⣄⠀⢠⣾⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⣶⣴⡿⠋⠀⠀⠀⠀⠀⠀⠀⠈⠉⢻⣷⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣷⡾⠟⠋⠉⠀⠀⠀⠀⠀⠀⠀⠹⡻⣷⡿⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣻⡿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⡿⢻⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢧⠹⣷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⠁⢸⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠀⢻⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⠀⠘⠃⠀⠀⠀⠀⠀⠀⠀⠀⢠⢿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠆⢸⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡷⣄⠀⠀⠀⠀⠀⠀⠀⢀⡴⠃⣼⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠃⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⣿⠀⣴⡾⠟⠻⢷⣦⣴⠶⢶⣦⣼⣿⣎⠑⠒⠠⠠⠤⠐⠚⠁⣠⣾⣿⠿⠛⠿⣶⣤⡶⠶⣶⣤⣾⠿⠛⠻⣷⣄⢸⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣿⣿⠀⠀⠀⢰⡿⠁⠀⠀⠙⣿⡚⠛⢷⣦⣤⣀⣀⣠⣤⣶⣿⣿⡇⠀⠀⠀⣿⠏⠀⠀⠀⢻⣧⠀⢀⡴⢉⣿⡿⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⠿⢶⣶⣼⣷⣤⣤⣤⣴⣿⣶⣶⡾⠿⠟⠉⠉⠉⠁⠀⠈⠛⢿⠿⣶⣦⣿⣦⣤⣤⣤⣾⣿⣿⣷⠿⡟⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EqcOpdyv-rii"
   },
   "outputs": [],
   "source": [
    "among_us='''\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣤⣤⣤⣤⣤⣶⣦⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿⠛⠉⠙⠛⠛⠛⠛⠻⢿⣿⣷⣮⡀⠀⠀⡘⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⣼⣿⠋⠑⠀⠀⠀⠀⠄⠀⢀⣀⣀⠈⢻⣿⣿⡄⠠⡀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣸⣿⡏⠀⠀⠀⣠⣶⣾⣿⣿⣿⠿⠿⠿⢿⣿⣿⣿⣄⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣿⣿⠁⠀⠀⢰⣿⣿⣯⠁⠖⡆⠀⠀⠀⢀⡀⠈⠙⢿⣷⡄⠀⠀\n",
    "⠀⠀⣀⣤⣴⣶⣷⣿⡿⠀⠀⠀⢸⣿⣿⣿⣞⠀⠊⠀⠀⠀⠀⡘⠁⠀⠆⣿⣷⠀⠀\n",
    "⠀⢰⣿⡟⠋⠉⣹⣿⡇⠀⠀⠀⠘⣿⣿⣿⣿⣷⣦⣤⣼⣵⣶⣶⣶⣶⣿⣿⣿⠀⠀\n",
    "⠀⢸⣿⡇⠀⠀⣿⣿⡇⠀⠀⠲⠀⠹⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠃⠀⠀\n",
    "⠀⣸⣿⡇⠀⡐⣿⣿⡇⠀⠀⡀⠀⠀⠉⠻⠿⣿⣿⣿⣿⡿⠿⡿⡛⢻⣿⡗⢾⡿⣿\n",
    "⠀⣿⣿⠁⠀⠄⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠁⠀⠀⠁⠀⠀⠀⠀⢸⣿⣯⠀⠀⣾\n",
    "⠀⣿⣿⠀⠀⠀⣿⣿⡇⠀⠀⠀⠈⠀⠀⢠⠂⠀⠀⠀⠄⠀⠀⠀⠁⢽⣿⣿⠀⠀⢸\n",
    "⠀⣿⣿⠀⠀⠘⣿⣿⡇⠀⠀⠀⠁⠀⠀⠃⠀⠀⠀⡀⠄⠀⠀⡆⡔⢻⣿⣿⠀⠀⣾\n",
    "⠀⢿⣿⡆⠀⠀⣿⣿⡇⠀⠀⠁⠀⠈⠀⠀⠀⠀⠀⠁⠀⠀⣐⠡⠀⢸⣿⡇⠀⠶⡏\n",
    "⠀⠸⣿⣧⡀⡅⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠭⠀⠃⠨⣿⣿⣳⠠⠋⠏\n",
    "⠀⠀⠛⢿⣿⣿⣿⣿⣇⠀⠀⠀⠀⠀⣲⣿⣿⣷⣶⣶⣷⣿⠿⠀⢠⣿⣿⢰⠁⠀⠀\n",
    "⠀⠀⠀⠀⢀⠀⠀⣿⣿⠀⠀⠀⠀⠀⣿⣿⡇⠀⣽⣿⡏⠁⠒⢀⢸⣿⡇⠀⠁⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣿⣿⠀⠀⠀⠀⠀⣿⣿⡇⠀⢹⣿⡆⠀⠉⠀⣸⣿⠇⠀⠐⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⢿⣿⣦⣄⣀⣠⣴⣿⣿⠁⠀⠈⠻⣿⣿⣿⣿⡿⠏⠀⠀⠀⠀⠀\n",
    "⠈⠀⠀⠀⠀⠀⠀⠈⠛⠻⠿⠿⠿⠿⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FPv_eeXm-4fw"
   },
   "outputs": [],
   "source": [
    "def draw_animal(name: str):\n",
    "    allowed_animals = [\"among_us\", \"elephant\", \"panda\"]\n",
    "    if name not in allowed_animals:\n",
    "        raise ValueError(f\"Invalid animal name. Choose one of {allowed_animals}.\")\n",
    "    print(f\"Drawing...\")\n",
    "    print(eval(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKShoOH2BOwo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5KLhu3e41VdM"
   },
   "outputs": [],
   "source": [
    "def no_function_defined():\n",
    "  print(\"Sorry this tool isn't present in the current version , \\nwe'll work on it and release it soon,\\nTankyou you can continue your chat with model\\n\\n \")\n",
    "  print(\"\\n\" + \"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qh8i3Bunu7Rn"
   },
   "outputs": [],
   "source": [
    "# Static part of the function prompt\n",
    "function_prompt_template = '''\n",
    "Function:\n",
    "def write(num:int,word:str):\n",
    "  \"\"\"\n",
    "  writes the word num times\n",
    "  parameters:\n",
    "  -num (int): takes the number of times to print the word\n",
    "  -word (str): takes the word to print\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "Function:\n",
    "def draw_animal(name: str):\n",
    "    \"\"\"\n",
    "    allowed_animals = [\"among_us\", \"elephant\", \"panda\"]\n",
    "    draws the ascii image of the given animal\n",
    "    parameters:\n",
    "    -name (str): takes the name of the animal to draw\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "Function:\n",
    "def exit():\n",
    "  \"\"\"\n",
    "  it will exit the function call\n",
    "  usage : [\"thankyou\"] or words similar to these words:\n",
    "  example usage : user input - thankyou or im done or exit\n",
    "  function_called: exit()\n",
    "\n",
    "  return exit\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  user_query={query}\n",
    "'''\n",
    "full_prompt_static = \"this is a tool for agent work follow the documentation to call the function\\n\" + \\\n",
    "    function_prompt_template + \\\n",
    "    \"\\n\\n(based on the docstring give only the function call filled with paramters in it ) \" + \\\n",
    "    '''\\n\\n export it in this format\n",
    "example:\n",
    "function_called: name_of_the_function(parameters from the the user input)'''\n",
    "\n",
    "\n",
    "# Function:\n",
    "# def no_function_defined():\n",
    "#   \"\"\"\n",
    "#   this function is executed when no operation is defined by the user matches with the defined function present in this prompt ans it prints this message\n",
    "#   print(\"Sorry this tool isn't present in the current version , \\nwe'll work on it and release it soon,\\nTankyou you can continue your chat with model\\n\\n \")\n",
    "#   \"\"\"\n",
    "\n",
    "\n",
    "# \"\\n If user gives any input and it doesnt shows similarity to the defined functions below then chat him like a LLM chat bot and answer his question and also ue no_function_defined()\\n\\n\"+\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Eqdgo4QoKiAb"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  thankyou\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_called: exit()\n",
      "\n",
      "Exit function detected!\n",
      "Clearing this message box for new input in 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "no_exit=True\n",
    "while no_exit:\n",
    "    query = input(\"Enter your query: \")\n",
    "    full_prompt = full_prompt_static.format(query=query)\n",
    "    chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Act as an AI agent\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Run the expected tool correctely\"},\n",
    "        ]\n",
    "    )\n",
    "    response = chat.send_message(full_prompt)\n",
    "    response_by_llm=response.text\n",
    "    print(response_by_llm)\n",
    "    function_calls = re.findall(r'function_called: .*', response_by_llm)\n",
    "\n",
    "    # if function_calls.split(\"function_called:\")[1].split(\"\\n\")[0] == 'exit':\n",
    "    #     break\n",
    "    for function_call in function_calls:\n",
    "    # Split and process the specific string\n",
    "      if function_call.split(\"function_called:\")[1].split(\"\\n\")[0].strip() == \"exit()\":\n",
    "          print(\"Exit function detected!\")\n",
    "          no_exit=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for fc in function_calls:\n",
    "        eval(fc.split(\"function_called:\")[1].split(\"\\n\")[0].replace(\"`\", \"\"))\n",
    "    sec=5\n",
    "    print(f\"Clearing this message box for new input in {sec} seconds\")\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
